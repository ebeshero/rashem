{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5fd474-5247-402c-aa6a-4177f9e47a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raasheemishra/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " saved: /Users/raasheemishra/draculaDaily/dracula-weekly-1.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-weekly-1.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-may-5-836.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-may-5-836.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-may-4-116.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-may-4-116.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-may-3-8f9.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-may-3-8f9.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-daily-starts-in-two-weeks-e93.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-daily-starts-in-two-weeks-e93.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/welcome-to-the-offseason.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/welcome-to-the-offseason.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-7-years-later-d45.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-7-years-later-d45.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-november-6-ff5.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-november-6-ff5.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-november-5-e32.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-november-5-e32.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-november-4-e8c.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-november-4-e8c.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-november-3-103.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-november-3-103.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-november-2-fba.txt\n",
      " saved: /Users/raasheemishra/draculaDaily/dracula-november-2-fba.txt\n",
      "all posts saved as plain text!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "\n",
    "archive_url = \"https://draculadaily.substack.com/archive\"\n",
    "\n",
    "def get_dracula_posts():\n",
    "    # Fetch the archive page\n",
    "    r = requests.get(archive_url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    # Create folder\n",
    "    folder = os.path.join(os.getcwd(), 'draculaDaily')\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Collect links to each post\n",
    "    posts = soup.find_all('a', href=True)\n",
    "    for post in posts:\n",
    "        href = post['href']\n",
    "        if href.startswith(\"https://draculadaily.substack.com/p/\"):\n",
    "            download_post_text(href, folder)\n",
    "\n",
    "    print(\"all posts saved as plain text!\")\n",
    "\n",
    "def download_post_text(url, folder):\n",
    "    # Fetch individual post\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        print(f\"could not download {url}\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    # Extract the title or slug for filename\n",
    "    slug = url.rstrip('/').split('/')[-1]\n",
    "    safe_slug = re.sub(r'\\W+', '-', slug)\n",
    "\n",
    "    # Try to extract the main story content\n",
    "    article = soup.find('div', class_='body')  # substack post content is in div.body\n",
    "    if not article:\n",
    "        print(f\"no article content found in {url}\")\n",
    "        return\n",
    "\n",
    "    # Get just the text, stripped of HTML\n",
    "    text = article.get_text(separator='\\n', strip=True)\n",
    "\n",
    "    # Save to .txt file\n",
    "    filepath = os.path.join(folder, f\"{safe_slug}.txt\")\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "\n",
    "    print(f\" saved: {filepath}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_dracula_posts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e3dd54-cd9c-4577-8be2-845ae8726155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
